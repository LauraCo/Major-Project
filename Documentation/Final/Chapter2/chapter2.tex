%\addcontentsline{toc}{chapter}{Development Process}
\chapter{Experiment Methods}

%This section should discuss the overall hypothesis being tested and justify the approach selected in the context of the research area.  Describe the experiment design that has been selected and how measurements and comparisons of results are to be made.%You should concentrate on the more important aspects of the method. Present an overview before going into detail. As well as describing the methods adopted, discuss other approaches that were considered. You might also discuss areas that you had to revise after some investigation.%You should also identify any support tools that you used. You should discuss your choice of implementation tools or simulation tools. For any code that you have written, you can talk about languages and related tools. For any simulation and analysis tools, identify the tools and how they are used on the project.%If your project includes some engineering (hardware, software, firmware, or a mixture) to support the experiments, include details in your report about your design and implementation. You should discuss with your supervisor whether it is better to include a different top-level section to describe any engineering work.\section{Overview}This section will provide an overview of how the experimental elements of this project were implemented, in alignment with the research questions posed in \ref{ssec:research-qs}.\subsection{Pixel Membership}\label{sssec:member}From the analysis of the planned fuzzy entropy algorithms, one major task to be undertaken would be to calculate the membership of each pixel. Membership stems from fuzzy set theory, as outlined in Subsection \ref{ssec:fuzzy-entropy}.There are two common methods to modelling degrees of membership. The first is to manually define the category boundaries, so in the case of trapezoidal functions, the two bases and the two shoulders. The other solution would be to iterate over the image pixel values and to computationally build the membership functions to evenly distribute these pixel values, as in Strange and Mac Parthal\'ain \cite{Mac_Parthalain_Strange_2013}. Whilst this is the preferred method for being dynamic in its calculations, it is also more computationally expensive as pre-processing of the image would have to be completed before the \Gls{Congealing} algorithm could be run.Taking the computational expense into account, for grey-level pixel values, ranging from 0 (black) to 255 (white), two or three trapezium functions would be sufficient, therefore modeling `Low', `Medium' and `High' grey-level values. The bases and shoulders would be statically defined, as in Figure \ref{fig:3-trapeziums} and Table \ref{table:values}. For Non-Probabilistic entropy the highest membership for each pixel from each of the three trapezia would be taken as the membership degree. Hybrid entropy would take a slightly different approach, which will be covered later.\begin{figure}[H]  \center  \includegraphics[scale=0.4]{Chapter2/hybrid-img/3_traps.png}  \caption{3 trapezium-shaped membership sets}  \label{fig:3-trapeziums}\end{figure}\begin{table}  \center  \begin{tabular}{ |l|l|l|l|l|l|l|l|l| }    \hline    \multicolumn{4}{|c|}{Low} & \multicolumn{5}{|c|}{} \\    \hline    \multicolumn{2}{|c|}{} & \multicolumn{5}{|c|}{Medium} & \multicolumn{2}{|c|}{}  \\    \hline    \multicolumn{5}{|c|}{} & \multicolumn{4}{|c|}{High} \\    \hline    0 & 50 & 60 & 70.4 & 85 & 170 & 195 & 205 & 255 \\    \hline    \cellcolor[gray]{0} & \cellcolor[gray]{0.19} & \cellcolor[gray]{0.24} & \cellcolor[gray]{0.28} & \cellcolor[gray]{0.33} & \cellcolor[gray]{0.66} & \cellcolor[gray]{0.76} & \cellcolor[gray]{0.8} & \cellcolor[gray]{1} \\ \hline  \end{tabular}\caption{Intepretation of the fuzzy sets across greyscale values}\label{table:values}\end{table}\subsection{Fuzzy entropy choices}\textbf{Chosen algorithms:}\begin{itemize}  \item Non-Probabilistic Entropy  \item Hybrid Entropy\end{itemize}Given the simplistic nature of Non-Probabilistic entropy, this was one of the chosen fuzzy entropy algorithms to be implemented in the project.Hybrid entropy was chosen for implementation in this project due to its hybrid nature (implementing both Probabilistic and Possibilistic uncertainty) and for its simplification nature - in the absence of fuzziness, then $E_0$ and $E_1$ reduce to $p_0$ and $p_1$ respectively, therefore classical Shannon entropy. This is especially useful in image processing, and other such areas which deal with a lot of noise.Additionally, Shannon Entropy has already been implemented by Learned-Miller`s Congealing algorithm \cite{joint-alignment}, so this offers a non-fuzzy alternative to image alignment.\textbf{Discarded algorithms:}\begin{itemize}  \item Fuzzy Shannon Entropy  \item Higher Order Entropy\end{itemize}The initial plan was to implement the Fuzzy Shannon entropy algorithm in the project - however after further investigation which revealed that the algorithm does not model Probabilistic uncertainty - it was decided that it was to be excluded.This project does not implement Higher Order Fuzzy Entropy due to the computational-overhead needed to run - especially on images with as much detail as a mammogram.\subsection{Image Alignment choice}\textbf{Image Alignment choice:}\begin{itemize}    \item \Gls{Congealing} algorithm\end{itemize}As this project will be working with mammograms, something with little variation nor inconsistency, \Gls{Congealing} is the perfect, light-weight image alignment algorithm to build upon, especially as the demonstration code available for research has a Shannon entropy implementation already developed.\textbf{Discarded Image Alignment choice:}\begin{itemize}    \item Least squares \gls{Congealing}    \item Joint Alignment of Complex Images\end{itemize}Least squares \gls{Congealing} algorithm was disregarded for this project due to the preference to focus upon entropy-based alignment algorithms and the computational costs that the authors themselves regard to be a drawback of their algorithm.The Complex Images implementation of \Gls{Congealing} was quickly identified as overly complex for this project. The original \Gls{Congealing} algorithm was more appropriate for grey-scale mammograms, with a consistent canonical pose.